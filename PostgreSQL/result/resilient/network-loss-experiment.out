W0921 10:12:27.476807       1 client_config.go:541] Neither --kubeconfig nor --master was specified.  Using the inClusterConfig.  This might not work.
time="2021-09-21T10:12:27Z" level=info msg="Experiment Name: pod-network-loss"
time="2021-09-21T10:12:27Z" level=info msg="[PreReq]: Getting the ENV for the  experiment"
time="2021-09-21T10:12:27Z" level=info msg="[PreReq]: Updating the chaos result of pod-network-loss experiment (SOT)"
time="2021-09-21T10:12:29Z" level=info msg="The application information is as follows\n" Namespace=postgres Label="application=spilo" Ramp Time=0
time="2021-09-21T10:12:29Z" level=info msg="[Status]: Verify that the AUT (Application Under Test) is running (pre-chaos)"
time="2021-09-21T10:12:29Z" level=info msg="[Status]: Checking whether application containers are in ready state"
time="2021-09-21T10:12:29Z" level=info msg="[Status]: The Container status are as follows" container=postgres Pod=postgres-application-0 Readiness=true
time="2021-09-21T10:12:29Z" level=info msg="[Status]: The Container status are as follows" container=postgres Pod=postgres-application-1 Readiness=true
time="2021-09-21T10:12:31Z" level=info msg="[Status]: Checking whether application pods are in running state"
time="2021-09-21T10:12:31Z" level=info msg="[Status]: The status of Pods are as follows" Pod=postgres-application-0 Status=Running
time="2021-09-21T10:12:31Z" level=info msg="[Status]: The status of Pods are as follows" Pod=postgres-application-1 Status=Running
time="2021-09-21T10:12:33Z" level=info msg="[Probe]: The cmd probe information is as follows" Phase=PreChaos Name=check Command="python3 test.py" Comparator="{int == 0}" Source="kaleoum/postgres:c2" Run Properties="{40 10 3 15 0 false}" Mode=Continuous
time="2021-09-21T10:12:33Z" level=info msg="[Status]: Checking the status of the probe pod"
time="2021-09-21T10:12:33Z" level=info msg="[Status]: Checking whether application containers are in ready state"
time="2021-09-21T10:12:35Z" level=info msg="[Status]: Checking whether application pods are in running state"
time="2021-09-21T10:12:57Z" level=info msg="[Status]: The status of Pods are as follows" Pod=pod-network-loss-probe-adkjps Status=Running
time="2021-09-21T10:12:59Z" level=info msg="[Probe]: The prometheus probe information is as follows" Endpoint="http://prometheus-k8s.monitoring.svc.cluster.local:9090" Comparator="{ >= 10}" Run Properties="{2 2 2 1 0 false}" Mode=Continuous Phase=PreChaos Name=prom Query="sum(rate(pg_stat_database_tup_inserted{datname=~\\\"postgres\\\"}[90s]))"
time="2021-09-21T10:12:59Z" level=info msg="[Probe]: {Actual value: 64.81176470588235}, {Expected value: 10}, {Operator: >=}"
time="2021-09-21T10:12:59Z" level=info msg="[Chaos]:Number of pods targeted: 1"
time="2021-09-21T10:12:59Z" level=info msg="Target pods list for chaos, [postgres-application-0]"
time="2021-09-21T10:12:59Z" level=info msg="[Info]: Details of application under chaos injection" ContainerName=postgres PodName=postgres-application-0 NodeName=ip-192-168-58-70.us-west-2.compute.internal
time="2021-09-21T10:12:59Z" level=info msg="[Status]: Checking the status of the helper pods"
time="2021-09-21T10:13:00Z" level=info msg="[Probe]: {Actual value: 0}, {Expected value: 0}, {Operator: ==}"
time="2021-09-21T10:13:11Z" level=info msg="pod-network-loss-helper-eonqel helper pod is in Running state"
time="2021-09-21T10:13:13Z" level=info msg="[Wait]: waiting till the completion of the helper pod"
time="2021-09-21T10:13:13Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:15Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:16Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:17Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:18Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:19Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:20Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:21Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:22Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:23Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:24Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:25Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:26Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:27Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:28Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:29Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:30Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:31Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:32Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:33Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:34Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:35Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:36Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:37Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:38Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:39Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:40Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:41Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:42Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:43Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:44Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:45Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:46Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:47Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:48Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:49Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:50Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:51Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:52Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:53Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:54Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:55Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:56Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:57Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:58Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:13:59Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:00Z" level=info msg="helper pod status: Running"
Traceback (most recent call last):
  File "//test.py", line 61, in <module>
    Main()
  File "//test.py", line 56, in Main
    db = DBDetails()
  File "//test.py", line 24, in __init__
    self.db_conn      = psycopg2.connect(host=t_host, port=t_port, dbname=t_dbname, user=t_name_user, password=t_password)
  File "/usr/local/lib/python3.9/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not connect to server: No route to host
	Is the server running on host "postgres-application.postgres.svc" (10.100.2.193) and accepting
	TCP/IP connections on port 5432?

time="2021-09-21T10:14:01Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:02Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:03Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:04Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:05Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:06Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:07Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:08Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:09Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:10Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:11Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:12Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:13Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:14Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:15Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:16Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:17Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:18Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:19Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:20Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:21Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:22Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:23Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:24Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:25Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:26Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:27Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:28Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:29Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:30Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:31Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:32Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:33Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:34Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:35Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:36Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:37Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:38Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:39Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:40Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:41Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:42Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:43Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:44Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:45Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:46Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:47Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:48Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:49Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:50Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:51Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:52Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:53Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:54Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:55Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:56Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:57Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:58Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:14:59Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:15:00Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:15:01Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:15:02Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:15:03Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:15:04Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:15:05Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:15:06Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:15:07Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:15:08Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:15:09Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:15:10Z" level=info msg="helper pod status: Running"
time="2021-09-21T10:15:11Z" level=info msg="helper pod status: Succeeded"
time="2021-09-21T10:15:11Z" level=info msg="[Status]: The running status of Pods are as follows" Pod=pod-network-loss-helper-eonqel Status=Succeeded
time="2021-09-21T10:15:12Z" level=info msg="[Cleanup]: Deleting all the helper pod"
time="2021-09-21T10:15:15Z" level=info msg="[Confirmation]: pod-network-loss chaos has been injected successfully"
time="2021-09-21T10:15:15Z" level=info msg="[Status]: Verify that the AUT (Application Under Test) is running (post-chaos)"
time="2021-09-21T10:15:15Z" level=info msg="[Status]: Checking whether application containers are in ready state"
time="2021-09-21T10:15:15Z" level=info msg="[Status]: The Container status are as follows" container=postgres Pod=postgres-application-0 Readiness=true
time="2021-09-21T10:15:15Z" level=info msg="[Status]: The Container status are as follows" Readiness=true container=postgres Pod=postgres-application-1
time="2021-09-21T10:15:17Z" level=info msg="[Status]: Checking whether application pods are in running state"
time="2021-09-21T10:15:17Z" level=info msg="[Status]: The status of Pods are as follows" Pod=postgres-application-0 Status=Running
time="2021-09-21T10:15:17Z" level=info msg="[Status]: The status of Pods are as follows" Pod=postgres-application-1 Status=Running
time="2021-09-21T10:15:19Z" level=info msg="[Probe]: check probe has been Passed ðŸ˜„ " ProbeInstance=PostChaos ProbeStatus=Passed ProbeName=check ProbeType=cmdProbe
time="2021-09-21T10:15:21Z" level=info msg="[Probe]: prom probe has been Passed ðŸ˜„ " ProbeName=prom ProbeType=promProbe ProbeInstance=PostChaos ProbeStatus=Passed
time="2021-09-21T10:15:21Z" level=info msg="[Probe]: check probe has been Passed ðŸ˜„ " ProbeName=check ProbeType=cmdProbe ProbeInstance=PostChaos ProbeStatus=Passed
time="2021-09-21T10:15:23Z" level=info msg="[Probe]: prom probe has been Passed ðŸ˜„ " ProbeName=prom ProbeType=promProbe ProbeInstance=PostChaos ProbeStatus=Passed
time="2021-09-21T10:15:23Z" level=info msg="[The End]: Updating the chaos result of pod-network-loss experiment (EOT)"
