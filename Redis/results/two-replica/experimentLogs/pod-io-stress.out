W0103 11:06:23.699729       1 client_config.go:541] Neither --kubeconfig nor --master was specified.  Using the inClusterConfig.  This might not work.
time='2022-01-03T11:06:23Z' level=info msg='Experiment Name: pod-io-stress'
time='2022-01-03T11:06:23Z' level=info msg='[PreReq]: Getting the ENV for the pod-io-stress experiment'
time='2022-01-03T11:06:25Z' level=info msg='[PreReq]: Updating the chaos result of pod-io-stress experiment (SOT)'
time='2022-01-03T11:06:27Z' level=info msg='The application information is as follows' Namespace=redis Label='app=redis' Chaos Duration=100 FilesystemUtilizationPercentage=100 NumberOfWorkers=7
time='2022-01-03T11:06:27Z' level=info msg='[Status]: Verify that the AUT (Application Under Test) is running (pre-chaos)'
time='2022-01-03T11:06:27Z' level=info msg='[Status]: Checking whether application containers are in ready state'
time='2022-01-03T11:06:27Z' level=info msg='[Status]: The Container status are as follows' container=redis Pod=redis-0 Readiness=true
time='2022-01-03T11:06:27Z' level=info msg='[Status]: The Container status are as follows' Readiness=true container=redis-exporter Pod=redis-0
time='2022-01-03T11:06:27Z' level=info msg='[Status]: The Container status are as follows' Pod=redis-1 Readiness=true container=redis
time='2022-01-03T11:06:27Z' level=info msg='[Status]: The Container status are as follows' container=redis-exporter Pod=redis-1 Readiness=true
time='2022-01-03T11:06:29Z' level=info msg='[Status]: Checking whether application pods are in running state'
time='2022-01-03T11:06:29Z' level=info msg='[Status]: The status of Pods are as follows' Status=Running Pod=redis-0
time='2022-01-03T11:06:29Z' level=info msg='[Status]: The status of Pods are as follows' Pod=redis-1 Status=Running
time='2022-01-03T11:06:33Z' level=info msg='[Probe]: The k8s probe information is as follows' Run Properties='{1 1 1 1 0 false}' Mode=Continuous Phase=PreChaos Name=check-redis-db-cr-status Inputs='{ v1 pods redis status.phase=Running app=redis present}'
time='2022-01-03T11:06:33Z' level=info msg='[Probe]: The prometheus probe information is as follows' Mode=Continuous Phase=PreChaos Name=check-probe-success Query='sum(rate(redis_commands_total{}[40s]))' Endpoint='http://prometheus-k8s.monitoring.svc.cluster.local:9090' Comparator='{ >= 1200}' Run Properties='{3 2 3 0 0 false}'
time='2022-01-03T11:06:33Z' level=info msg='[Probe]: The cmd probe information is as follows' Command='python3 -u redis-cmd.py' Comparator='{string equal 0}' Source='{kaleoum/kgh-load:j6 false}' Run Properties='{1 1 1 1 0 false}' Mode=Continuous Phase=PreChaos Name=check
time='2022-01-03T11:06:33Z' level=info msg='[Probe]: {Actual value: 1349.8285714285716}, {Expected value: 1200}, {Operator: >=}'
time='2022-01-03T11:06:34Z' level=info msg='[Status]: Checking the status of the probe pod'
time='2022-01-03T11:06:34Z' level=info msg='[Status]: Checking whether application containers are in ready state'
time='2022-01-03T11:06:36Z' level=info msg='[Status]: Checking whether application pods are in running state'
time='2022-01-03T11:06:40Z' level=info msg='[Status]: The status of Pods are as follows' Status=Running Pod=pod-io-stress-probe-wmfvee
time='2022-01-03T11:06:42Z' level=info msg='[Chaos]:Number of pods targeted: 1'
time='2022-01-03T11:06:42Z' level=info msg='[Info]: Target pods list for chaos, [redis-0]'
time='2022-01-03T11:06:42Z' level=info msg='[Probe]: {Actual value: 0}, {Expected value: 0}, {Operator: equal}'
time='2022-01-03T11:06:44Z' level=info msg='[Info]: Details of application under chaos injection' ContainerName=redis PodName=redis-0 NodeName=minikube
time='2022-01-03T11:06:44Z' level=info msg='[Status]: Checking the status of the helper pods'
time='2022-01-03T11:06:44Z' level=error msg='The check-probe-success prom probe has been Failed, err: {actual value: 1182.6285714285718} is not greater than or equal to {expected value: 1200}'
time='2022-01-03T11:06:46Z' level=error msg='The check-probe-success prom probe has been Failed, err: {actual value: 1182.6860081968555} is not greater than or equal to {expected value: 1200}'
time='2022-01-03T11:06:48Z' level=error msg='The check-probe-success prom probe has been Failed, err: {actual value: 1182.6860081968555} is not greater than or equal to {expected value: 1200}'
time='2022-01-03T11:06:50Z' level=error msg='The check-probe-success prom probe has been Failed, err: {actual value: 1185.0002939111412} is not greater than or equal to {expected value: 1200}'
time='2022-01-03T11:06:52Z' level=info msg='pod-io-stress-helper-ofikzo helper pod is in Running state'
time='2022-01-03T11:06:52Z' level=error msg='The check-probe-success prom probe has been Failed, err: {actual value: 1185.0280515325505} is not greater than or equal to {expected value: 1200}'
time='2022-01-03T11:06:54Z' level=info msg='[Wait]: waiting till the completion of the helper pod'
time='2022-01-03T11:06:54Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:06:54Z' level=error msg='The check-probe-success prom probe has been Failed, err: {actual value: 1145.9709086754076} is not greater than or equal to {expected value: 1200}'
time='2022-01-03T11:06:55Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:06:56Z' level=error msg='The check-probe-success prom probe has been Failed, err: {actual value: 1145.9712057333861} is not greater than or equal to {expected value: 1200}'
time='2022-01-03T11:06:56Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:06:58Z' level=error msg='The check-probe-success prom probe has been Failed, err: {actual value: 1145.9712057333861} is not greater than or equal to {expected value: 1200}'
time='2022-01-03T11:06:58Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:06:59Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:00Z' level=error msg='The check-probe-success prom probe has been Failed, err: {actual value: 1145.9712057333861} is not greater than or equal to {expected value: 1200}'
time='2022-01-03T11:07:00Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:02Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:03Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:04Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:06Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:08Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:10Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:12Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:13Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:15Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:17Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:18Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:19Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:20Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:21Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:22Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:23Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:24Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:28Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:29Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:31Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:33Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:34Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:36Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:37Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:38Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:40Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:42Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:44Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:45Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:46Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:47Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:49Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:51Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:52Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:53Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:54Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:55Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:56Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:58Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:07:59Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:01Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:02Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:03Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:05Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:07Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:08Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:09Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:11Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:13Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:15Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:16Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:18Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:19Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:20Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:21Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:24Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:26Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:28Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:30Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:32Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:34Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:37Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:40Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:41Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:43Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:44Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:46Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:48Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:50Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:51Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:52Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:54Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:56Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:57Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:58Z' level=info msg='helper pod status: Running'
time='2022-01-03T11:08:59Z' level=info msg='helper pod status: Succeeded'
time='2022-01-03T11:08:59Z' level=info msg='[Status]: The running status of Pods are as follows' Status=Succeeded Pod=pod-io-stress-helper-ofikzo
time='2022-01-03T11:09:00Z' level=info msg='[Cleanup]: Deleting all the helper pod'
time='2022-01-03T11:09:02Z' level=info msg='[Confirmation]: pod-io-stress chaos has been injected successfully'
time='2022-01-03T11:09:02Z' level=info msg='[Status]: Verify that the AUT (Application Under Test) is running (post-chaos)'
time='2022-01-03T11:09:02Z' level=info msg='[Status]: Checking whether application containers are in ready state'
time='2022-01-03T11:09:02Z' level=info msg='[Status]: The Container status are as follows' Pod=redis-0 Readiness=true container=redis
time='2022-01-03T11:09:02Z' level=info msg='[Status]: The Container status are as follows' container=redis Pod=redis-1 Readiness=true
time='2022-01-03T11:09:04Z' level=info msg='[Status]: Checking whether application pods are in running state'
time='2022-01-03T11:09:04Z' level=info msg='[Status]: The status of Pods are as follows' Pod=redis-0 Status=Running
time='2022-01-03T11:09:04Z' level=info msg='[Status]: The status of Pods are as follows' Pod=redis-1 Status=Running
time='2022-01-03T11:09:08Z' level=info msg='[Probe]: check-redis-db-cr-status probe has been Passed ðŸ˜„ ' ProbeType=k8sProbe ProbeInstance=PostChaos ProbeStatus=Passed ProbeName=check-redis-db-cr-status
time='2022-01-03T11:09:08Z' level=error msg='[Probe]: check-probe-success probe has been Failed ðŸ˜¢ ' ProbeType=promProbe ProbeInstance=PostChaos ProbeStatus=Failed ProbeName=check-probe-success
time='2022-01-03T11:09:08Z' level=info msg='[Probe]: check probe has been Passed ðŸ˜„ ' ProbeName=check ProbeType=cmdProbe ProbeInstance=PostChaos ProbeStatus=Passed
time='2022-01-03T11:09:10Z' level=info msg='[Probe]: check-redis-db-cr-status probe has been Passed ðŸ˜„ ' ProbeStatus=Passed ProbeName=check-redis-db-cr-status ProbeType=k8sProbe ProbeInstance=PostChaos
time='2022-01-03T11:09:10Z' level=error msg='[Probe]: check-probe-success probe has been Failed ðŸ˜¢ ' ProbeType=promProbe ProbeInstance=PostChaos ProbeStatus=Failed ProbeName=check-probe-success
time='2022-01-03T11:09:10Z' level=info msg='[Probe]: check probe has been Passed ðŸ˜„ ' ProbeName=check ProbeType=cmdProbe ProbeInstance=PostChaos ProbeStatus=Passed
time='2022-01-03T11:09:12Z' level=info msg='[The End]: Updating the chaos result of pod-io-stress experiment (EOT)'
W0103 11:06:17.089862       1 client_config.go:541] Neither --kubeconfig nor --master was specified.  Using the inClusterConfig.  This might not work.
time='2022-01-03T11:06:17Z' level=info msg='Experiments details are as follows' Experiments List='[pod-io-stress]' Engine Name=pod-io-stresszs4vq appLabels='app=redis' appNs=redis appKind=deployment Service Account Name=litmus-admin Engine Namespace=litmus
time='2022-01-03T11:06:17Z' level=info msg='Getting the ENV Variables'
time='2022-01-03T11:06:17Z' level=info msg='Preparing to run Chaos Experiment: pod-io-stress'
time='2022-01-03T11:06:17Z' level=info msg='Started Chaos Experiment Name: pod-io-stress, with Job Name: pod-io-stress-k4l6bh'
time='2022-01-03T11:09:30Z' level=info msg='Chaos Pod Completed, Experiment Name: pod-io-stress, with Job Name: pod-io-stress-k4l6bh'
time='2022-01-03T11:09:32Z' level=info msg='Chaos Engine has been updated with result, Experiment Name: pod-io-stress'
time='2022-01-03T11:09:32Z' level=info msg='[skip]: skipping the job deletion as jobCleanUpPolicy is set to {retain}'